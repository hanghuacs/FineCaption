# FINECAPTION: Compositional Image Captioning Focusing on Wherever You Want at Any Granularity
<p align="center">
  <a href="https://arxiv.org/pdf/2411.15411"><img src="https://img.shields.io/badge/Paper-arXiv-b31b1b.svg"></a>
  &nbsp;
  <a href="https://hanghuacs.github.io/FineCaption/"><img src="https://img.shields.io/badge/Website-ProjectPage-A55D35"></a>
  &nbsp;
  <a href="https://huggingface.co/hhua2/finecaption"><img src="https://img.shields.io/badge/Resource-Dataset-EFBF6A.svg"></a>
</p>
![](/static/images/teaser-1.svg)
FINECAPTION is  a novel Vision-Language model with the improved capabilities of Attribute-Aware Regional
Captioning, Regional Dense Captioning, and Comprehensive Global Image Captioning. FINECAPTION can recognize arbitrary masks
as referential inputs and process high-resolution images.
## ✏️ Citation
```bibtex
@article{hua2024finecaption,
  title={FINECAPTION: Compositional Image Captioning Focusing on Wherever You Want at Any Granularity},
  author={Hua, Hang and Liu, Qing and Zhang, Lingzhi and Shi, Jing and Zhang, Zhifei and Wang, Yilin and Zhang, Jianming and Luo, Jiebo},
  journal={arXiv preprint arXiv:2411.15411},
  year={2024}
}
```
